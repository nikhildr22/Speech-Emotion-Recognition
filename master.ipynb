{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "master.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1hehg7ysiBm8YlAxUwNPK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhildr22/Speech-Emotion-Recognition/blob/master/master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDxKDAeHq3Eo",
        "colab_type": "code",
        "outputId": "2b57f6f1-94c4-4df1-f7e5-deed1d51ca9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2OyhiRinXTI",
        "colab_type": "code",
        "outputId": "105166df-f689-4853-8151-e46b30237a9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Audio_Speech_Actors_01-24.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxS4uqaWtesi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "606a3202-4d5f-493a-b154-f39f4ce7be95"
      },
      "source": [
        "!wget https://zenodo.org/record/1188976/files/Audio_Speech_Actors_01-24.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-05 00:22:31--  https://zenodo.org/record/1188976/files/Audio_Speech_Actors_01-24.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.184.117.155\n",
            "Connecting to zenodo.org (zenodo.org)|188.184.117.155|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 208468073 (199M) [application/octet-stream]\n",
            "Saving to: ‘Audio_Speech_Actors_01-24.zip’\n",
            "\n",
            "Audio_Speech_Actors 100%[===================>] 198.81M  98.8MB/s    in 2.0s    \n",
            "\n",
            "2020-04-05 00:22:34 (98.8 MB/s) - ‘Audio_Speech_Actors_01-24.zip’ saved [208468073/208468073]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGyGSDSGv0x2",
        "colab_type": "code",
        "outputId": "766c99dc-60e8-4db1-a880-465d7e4274b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!mkdir dataset\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Audio_Speech_Actors_01-24.zip  dataset\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zh9M1cffv9CZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q Audio_Speech_Actors_01-24.zip -d dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKzEkfDGwhLE",
        "colab_type": "code",
        "outputId": "89465ed2-12ba-46e6-888d-2203a3d5f067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Audio_Speech_Actors_01-24.zip  dataset\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AErppsmXyxyD",
        "colab_type": "code",
        "outputId": "8ce55d8a-5182-48a0-cf66-2059c29cf96f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "!pip install soundfile"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.3.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzhsncx9zO35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa\n",
        "from tqdm import tqdm\n",
        "import soundfile\n",
        "from scipy.io import wavfile\n",
        "import os, glob, pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX8xLyw9GPpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' directory to keep clean files '''\n",
        "!mkdir clean "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaoEOadGzTwb",
        "colab_type": "code",
        "outputId": "a1063021-6b7c-4dc1-b901-937c89d768f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "''' downsampling audio files to 16KHz and storing them in /clean directory ''' \n",
        "for f in tqdm(glob.glob(\"dataset/*/*\")):\n",
        "    signal, rate = librosa.load(path=f, sr=16000)\n",
        "    wavfile.write(filename='clean/'+f[-24:],rate=rate,data=signal)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1440/1440 [06:13<00:00,  3.86it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaDIo9MkzbxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DataFlair - Extract features (mfcc, chroma, mel) from a sound file\n",
        "def extract_feature(file_name, mfcc, chroma, mel):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        if chroma:\n",
        "            stft=np.abs(librosa.stft(X))\n",
        "        result=np.array([])\n",
        "        if mfcc:\n",
        "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "            result=np.hstack((result, mfccs))\n",
        "        if chroma:\n",
        "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "            result=np.hstack((result, chroma))\n",
        "        if mel:\n",
        "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "            result=np.hstack((result, mel))\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfOX_3jjzflf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DataFlair - Emotions in the RAVDESS dataset\n",
        "emotions={\n",
        "  '01':'neutral',\n",
        "  '02':'calm',\n",
        "  '03':'happy',\n",
        "  '04':'sad',\n",
        "  '05':'angry',\n",
        "  '06':'fearful',\n",
        "  '07':'disgust',\n",
        "  '08':'surprised'\n",
        "}\n",
        "#DataFlair - Emotions to observe (remove the prefix \"/\" to include that emotion)\n",
        "observed_emotions=['sad','/angry','happy','/neutral','/calm','/fearful','/disgust','/surprised']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUx8FVe6zjdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DataFlair - Load the data and extract features for each sound file\n",
        "\n",
        "def load_data(test_size=0.2):\n",
        "    x,y=[],[] \n",
        "    for file in tqdm(glob.glob(\"clean/*\")):\n",
        "        file_name=os.path.basename(file[-24:])\n",
        "#         print(file_name)\n",
        "        emotion=emotions[file_name.split(\"-\")[2]]\n",
        "        if emotion not in observed_emotions:\n",
        "            continue\n",
        "        try:\n",
        "            feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
        "            x.append(feature)\n",
        "            y.append(int(file_name.split(\"-\")[2]))\n",
        "        except:continue\n",
        "    return train_test_split(np.array(x), np.array(y), test_size=test_size, random_state=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkdO_qK4znlH",
        "colab_type": "code",
        "outputId": "3499412d-8000-4466-dd06-6edcc6898b13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#DataFlair - Split the dataset\n",
        "x_train,x_test,y_train,y_test=load_data(test_size=0.3)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1440/1440 [00:17<00:00, 83.15it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV5hZlNDzwvP",
        "colab_type": "code",
        "outputId": "62b50f49-02d2-4289-95ad-d899d279b819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#DataFlair - Get the shape of the training and testing datasets\n",
        "print((x_train.shape[0], x_test.shape[0]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(268, 116)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCWcNL950Xrl",
        "colab_type": "code",
        "outputId": "d2aca74e-31db-43fe-852a-8a6a275d5e7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#DataFlair - Get the number of features extracted\n",
        "print(f'Features extracted: {x_train.shape[1]}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features extracted: 180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrcyHTbU0aDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DataFlair - Initialize the Multi Layer Perceptron Classifier\n",
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500,verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnEx--Er0dc8",
        "colab_type": "code",
        "outputId": "eb4e5383-8d9b-4de5-806b-32c951c0fd90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#DataFlair - Train the model\n",
        "model.fit(x_train,y_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 8.24255835\n",
            "Iteration 3, loss = 2.97083333\n",
            "Iteration 4, loss = 7.20538565\n",
            "Iteration 5, loss = 4.80382261\n",
            "Iteration 6, loss = 1.26697725\n",
            "Iteration 7, loss = 3.05353355\n",
            "Iteration 8, loss = 3.30660637\n",
            "Iteration 9, loss = 1.67223613\n",
            "Iteration 10, loss = 1.21709124\n",
            "Iteration 11, loss = 1.62100209\n",
            "Iteration 12, loss = 1.05557190\n",
            "Iteration 13, loss = 1.12550941\n",
            "Iteration 14, loss = 1.37219417\n",
            "Iteration 15, loss = 0.82645888\n",
            "Iteration 16, loss = 0.79332262\n",
            "Iteration 17, loss = 0.71738275\n",
            "Iteration 18, loss = 0.53949213\n",
            "Iteration 19, loss = 0.58994836\n",
            "Iteration 20, loss = 0.49266813\n",
            "Iteration 21, loss = 0.53913077\n",
            "Iteration 22, loss = 0.56998907\n",
            "Iteration 23, loss = 0.46836829\n",
            "Iteration 24, loss = 0.43921354\n",
            "Iteration 25, loss = 0.51890044\n",
            "Iteration 26, loss = 0.47219534\n",
            "Iteration 27, loss = 0.66646038\n",
            "Iteration 28, loss = 0.44523890\n",
            "Iteration 29, loss = 0.67133304\n",
            "Iteration 30, loss = 0.42327584\n",
            "Iteration 31, loss = 0.57250755\n",
            "Iteration 32, loss = 0.39524565\n",
            "Iteration 33, loss = 0.41178456\n",
            "Iteration 34, loss = 0.38251127\n",
            "Iteration 35, loss = 0.38809571\n",
            "Iteration 36, loss = 0.52645192\n",
            "Iteration 37, loss = 0.37631087\n",
            "Iteration 38, loss = 0.45293069\n",
            "Iteration 39, loss = 0.37614455\n",
            "Iteration 40, loss = 0.53381967\n",
            "Iteration 41, loss = 0.37987938\n",
            "Iteration 42, loss = 0.45196010\n",
            "Iteration 43, loss = 0.37125276\n",
            "Iteration 44, loss = 0.35568853\n",
            "Iteration 45, loss = 0.37876604\n",
            "Iteration 46, loss = 0.37324511\n",
            "Iteration 47, loss = 0.37205439\n",
            "Iteration 48, loss = 0.40346815\n",
            "Iteration 49, loss = 0.34741749\n",
            "Iteration 50, loss = 0.53439821\n",
            "Iteration 51, loss = 0.41084155\n",
            "Iteration 52, loss = 0.74114152\n",
            "Iteration 53, loss = 0.36466603\n",
            "Iteration 54, loss = 0.37158321\n",
            "Iteration 55, loss = 0.40327957\n",
            "Iteration 56, loss = 0.34826897\n",
            "Iteration 57, loss = 0.40746350\n",
            "Iteration 58, loss = 0.33716121\n",
            "Iteration 59, loss = 0.34333203\n",
            "Iteration 60, loss = 0.32865686\n",
            "Iteration 61, loss = 0.33164771\n",
            "Iteration 62, loss = 0.34812017\n",
            "Iteration 63, loss = 0.42879338\n",
            "Iteration 64, loss = 0.32230546\n",
            "Iteration 65, loss = 0.47303221\n",
            "Iteration 66, loss = 0.38959806\n",
            "Iteration 67, loss = 0.33449352\n",
            "Iteration 68, loss = 0.33310281\n",
            "Iteration 69, loss = 0.35256805\n",
            "Iteration 70, loss = 0.45598193\n",
            "Iteration 71, loss = 0.30763739\n",
            "Iteration 72, loss = 0.38001770\n",
            "Iteration 73, loss = 0.31571469\n",
            "Iteration 74, loss = 0.45483508\n",
            "Iteration 75, loss = 0.30303110\n",
            "Iteration 76, loss = 0.49371152\n",
            "Iteration 77, loss = 0.31062126\n",
            "Iteration 78, loss = 0.40960215\n",
            "Iteration 79, loss = 0.31623458\n",
            "Iteration 80, loss = 0.32097766\n",
            "Iteration 81, loss = 0.49572392\n",
            "Iteration 82, loss = 0.33885252\n",
            "Iteration 83, loss = 0.45099144\n",
            "Iteration 84, loss = 0.36336871\n",
            "Iteration 85, loss = 0.37866292\n",
            "Iteration 86, loss = 0.40065020\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.01, batch_size=256, beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(300,), learning_rate='adaptive',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7wLIZ6a0gTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DataFlair - Predict for the test set\n",
        "y_pred=model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgyDehEE0vx3",
        "colab_type": "code",
        "outputId": "9e105103-1950-4fe0-8d27-49e52b8c0445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#DataFlair - Calculate the accuracy of our model\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "#DataFlair - Print the accuracy\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 69.83%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woCm2Cps0yKh",
        "colab_type": "code",
        "outputId": "f696a24b-e702-415a-89d1-2eb44ad366fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(268, 180)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqA0JoI00h4r",
        "colab_type": "code",
        "outputId": "7905244f-9d6c-42f3-fc6b-f192bacca8fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(268,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXAdR1WX00x1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "aad78c2f-b72a-4e56-8656-ebedaf2ff713"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Conv1D,Flatten# Neural network\n",
        "input_shape = (180,1)\n",
        "num_files = x_train.shape[0]\n",
        "x_train = x_train.reshape(num_files,180,1)\n",
        "y_train = y_train.reshape(num_files)\n",
        "model0 = Sequential()\n",
        "model0.add(Conv1D(32, kernel_size=(3), input_shape=input_shape))\n",
        "model0.add(Conv1D(64, kernel_size=(3)))\n",
        "model0.add(Conv1D(128, kernel_size=(3)))\n",
        "model0.add(Conv1D(64, kernel_size=(3)))\n",
        "model0.add(Conv1D(32, kernel_size=(3)))\n",
        "model0.add(Flatten())\n",
        "model0.add(Dense(128, activation='relu'))\n",
        "model0.add(Dense(12, activation='relu'))\n",
        "model0.add(Dense(9, activation='softmax'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsj9_-_RqMiU",
        "colab_type": "code",
        "outputId": "726afa0a-57fb-4885-c9c3-4e829927111a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "source": [
        "model0.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model0.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 178, 32)           128       \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 176, 64)           6208      \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 174, 128)          24704     \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 172, 64)           24640     \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 170, 32)           6176      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 5440)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               696448    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 12)                1548      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 9)                 117       \n",
            "=================================================================\n",
            "Total params: 759,969\n",
            "Trainable params: 759,969\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yajP5ddbrd1j",
        "colab_type": "code",
        "outputId": "bea266ec-e383-4e96-ddd6-99fcf4038d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model0.fit(x_train, y_train, epochs=85,verbose=1, batch_size=10)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/85\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "268/268 [==============================] - 15s 56ms/step - loss: 0.7869 - acc: 0.6231\n",
            "Epoch 2/85\n",
            "268/268 [==============================] - 0s 548us/step - loss: 0.5301 - acc: 0.7500\n",
            "Epoch 3/85\n",
            "268/268 [==============================] - 0s 556us/step - loss: 0.4077 - acc: 0.8433\n",
            "Epoch 4/85\n",
            "268/268 [==============================] - 0s 566us/step - loss: 0.4060 - acc: 0.8022\n",
            "Epoch 5/85\n",
            "268/268 [==============================] - 0s 553us/step - loss: 0.3275 - acc: 0.8582\n",
            "Epoch 6/85\n",
            "268/268 [==============================] - 0s 523us/step - loss: 0.2413 - acc: 0.9067\n",
            "Epoch 7/85\n",
            "268/268 [==============================] - 0s 529us/step - loss: 0.2323 - acc: 0.9030\n",
            "Epoch 8/85\n",
            "268/268 [==============================] - 0s 544us/step - loss: 0.2105 - acc: 0.9030\n",
            "Epoch 9/85\n",
            "268/268 [==============================] - 0s 535us/step - loss: 0.3164 - acc: 0.8769\n",
            "Epoch 10/85\n",
            "268/268 [==============================] - 0s 543us/step - loss: 0.3615 - acc: 0.8694\n",
            "Epoch 11/85\n",
            "268/268 [==============================] - 0s 545us/step - loss: 0.5161 - acc: 0.8209\n",
            "Epoch 12/85\n",
            "268/268 [==============================] - 0s 554us/step - loss: 0.1896 - acc: 0.9179\n",
            "Epoch 13/85\n",
            "268/268 [==============================] - 0s 534us/step - loss: 0.1486 - acc: 0.9254\n",
            "Epoch 14/85\n",
            "268/268 [==============================] - 0s 535us/step - loss: 0.1017 - acc: 0.9701\n",
            "Epoch 15/85\n",
            "268/268 [==============================] - 0s 574us/step - loss: 0.0705 - acc: 0.9776\n",
            "Epoch 16/85\n",
            "268/268 [==============================] - 0s 539us/step - loss: 0.0552 - acc: 0.9739\n",
            "Epoch 17/85\n",
            "268/268 [==============================] - 0s 536us/step - loss: 0.0925 - acc: 0.9776\n",
            "Epoch 18/85\n",
            "268/268 [==============================] - 0s 626us/step - loss: 0.0393 - acc: 0.9851\n",
            "Epoch 19/85\n",
            "268/268 [==============================] - 0s 554us/step - loss: 0.0416 - acc: 0.9888\n",
            "Epoch 20/85\n",
            "268/268 [==============================] - 0s 525us/step - loss: 0.1914 - acc: 0.9403\n",
            "Epoch 21/85\n",
            "268/268 [==============================] - 0s 517us/step - loss: 0.3882 - acc: 0.8881\n",
            "Epoch 22/85\n",
            "268/268 [==============================] - 0s 528us/step - loss: 0.3416 - acc: 0.8806\n",
            "Epoch 23/85\n",
            "268/268 [==============================] - 0s 563us/step - loss: 0.0893 - acc: 0.9627\n",
            "Epoch 24/85\n",
            "268/268 [==============================] - 0s 532us/step - loss: 0.0332 - acc: 0.9851\n",
            "Epoch 25/85\n",
            "268/268 [==============================] - 0s 569us/step - loss: 0.0181 - acc: 0.9963\n",
            "Epoch 26/85\n",
            "268/268 [==============================] - 0s 555us/step - loss: 0.0072 - acc: 1.0000\n",
            "Epoch 27/85\n",
            "268/268 [==============================] - 0s 516us/step - loss: 0.0038 - acc: 1.0000\n",
            "Epoch 28/85\n",
            "268/268 [==============================] - 0s 530us/step - loss: 0.0027 - acc: 1.0000\n",
            "Epoch 29/85\n",
            "268/268 [==============================] - 0s 539us/step - loss: 0.0025 - acc: 1.0000\n",
            "Epoch 30/85\n",
            "268/268 [==============================] - 0s 524us/step - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 31/85\n",
            "268/268 [==============================] - 0s 531us/step - loss: 0.0017 - acc: 1.0000\n",
            "Epoch 32/85\n",
            "268/268 [==============================] - 0s 560us/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 33/85\n",
            "268/268 [==============================] - 0s 589us/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 34/85\n",
            "268/268 [==============================] - 0s 520us/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 35/85\n",
            "268/268 [==============================] - 0s 512us/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 36/85\n",
            "268/268 [==============================] - 0s 527us/step - loss: 9.5427e-04 - acc: 1.0000\n",
            "Epoch 37/85\n",
            "268/268 [==============================] - 0s 517us/step - loss: 8.1889e-04 - acc: 1.0000\n",
            "Epoch 38/85\n",
            "268/268 [==============================] - 0s 531us/step - loss: 7.8843e-04 - acc: 1.0000\n",
            "Epoch 39/85\n",
            "268/268 [==============================] - 0s 559us/step - loss: 6.8384e-04 - acc: 1.0000\n",
            "Epoch 40/85\n",
            "268/268 [==============================] - 0s 565us/step - loss: 6.6641e-04 - acc: 1.0000\n",
            "Epoch 41/85\n",
            "268/268 [==============================] - 0s 508us/step - loss: 5.7417e-04 - acc: 1.0000\n",
            "Epoch 42/85\n",
            "268/268 [==============================] - 0s 510us/step - loss: 5.1087e-04 - acc: 1.0000\n",
            "Epoch 43/85\n",
            "268/268 [==============================] - 0s 518us/step - loss: 4.6867e-04 - acc: 1.0000\n",
            "Epoch 44/85\n",
            "268/268 [==============================] - 0s 586us/step - loss: 4.2656e-04 - acc: 1.0000\n",
            "Epoch 45/85\n",
            "268/268 [==============================] - 0s 528us/step - loss: 3.6872e-04 - acc: 1.0000\n",
            "Epoch 46/85\n",
            "268/268 [==============================] - 0s 589us/step - loss: 3.4451e-04 - acc: 1.0000\n",
            "Epoch 47/85\n",
            "268/268 [==============================] - 0s 552us/step - loss: 3.1958e-04 - acc: 1.0000\n",
            "Epoch 48/85\n",
            "268/268 [==============================] - 0s 520us/step - loss: 3.0958e-04 - acc: 1.0000\n",
            "Epoch 49/85\n",
            "268/268 [==============================] - 0s 525us/step - loss: 2.8293e-04 - acc: 1.0000\n",
            "Epoch 50/85\n",
            "268/268 [==============================] - 0s 516us/step - loss: 2.5327e-04 - acc: 1.0000\n",
            "Epoch 51/85\n",
            "268/268 [==============================] - 0s 527us/step - loss: 2.4754e-04 - acc: 1.0000\n",
            "Epoch 52/85\n",
            "268/268 [==============================] - 0s 514us/step - loss: 2.2488e-04 - acc: 1.0000\n",
            "Epoch 53/85\n",
            "268/268 [==============================] - 0s 535us/step - loss: 2.2218e-04 - acc: 1.0000\n",
            "Epoch 54/85\n",
            "268/268 [==============================] - 0s 526us/step - loss: 1.9937e-04 - acc: 1.0000\n",
            "Epoch 55/85\n",
            "268/268 [==============================] - 0s 525us/step - loss: 1.9234e-04 - acc: 1.0000\n",
            "Epoch 56/85\n",
            "268/268 [==============================] - 0s 545us/step - loss: 1.7650e-04 - acc: 1.0000\n",
            "Epoch 57/85\n",
            "268/268 [==============================] - 0s 509us/step - loss: 1.7529e-04 - acc: 1.0000\n",
            "Epoch 58/85\n",
            "268/268 [==============================] - 0s 516us/step - loss: 1.6864e-04 - acc: 1.0000\n",
            "Epoch 59/85\n",
            "268/268 [==============================] - 0s 535us/step - loss: 1.5191e-04 - acc: 1.0000\n",
            "Epoch 60/85\n",
            "268/268 [==============================] - 0s 537us/step - loss: 1.4410e-04 - acc: 1.0000\n",
            "Epoch 61/85\n",
            "268/268 [==============================] - 0s 553us/step - loss: 1.3427e-04 - acc: 1.0000\n",
            "Epoch 62/85\n",
            "268/268 [==============================] - 0s 519us/step - loss: 1.3365e-04 - acc: 1.0000\n",
            "Epoch 63/85\n",
            "268/268 [==============================] - 0s 532us/step - loss: 1.2830e-04 - acc: 1.0000\n",
            "Epoch 64/85\n",
            "268/268 [==============================] - 0s 522us/step - loss: 1.2580e-04 - acc: 1.0000\n",
            "Epoch 65/85\n",
            "268/268 [==============================] - 0s 507us/step - loss: 1.1762e-04 - acc: 1.0000\n",
            "Epoch 66/85\n",
            "268/268 [==============================] - 0s 522us/step - loss: 1.0469e-04 - acc: 1.0000\n",
            "Epoch 67/85\n",
            "268/268 [==============================] - 0s 547us/step - loss: 1.1094e-04 - acc: 1.0000\n",
            "Epoch 68/85\n",
            "268/268 [==============================] - 0s 596us/step - loss: 1.0503e-04 - acc: 1.0000\n",
            "Epoch 69/85\n",
            "268/268 [==============================] - 0s 520us/step - loss: 9.5994e-05 - acc: 1.0000\n",
            "Epoch 70/85\n",
            "268/268 [==============================] - 0s 524us/step - loss: 8.8104e-05 - acc: 1.0000\n",
            "Epoch 71/85\n",
            "268/268 [==============================] - 0s 525us/step - loss: 8.3971e-05 - acc: 1.0000\n",
            "Epoch 72/85\n",
            "268/268 [==============================] - 0s 524us/step - loss: 8.2804e-05 - acc: 1.0000\n",
            "Epoch 73/85\n",
            "268/268 [==============================] - 0s 517us/step - loss: 7.7568e-05 - acc: 1.0000\n",
            "Epoch 74/85\n",
            "268/268 [==============================] - 0s 541us/step - loss: 7.5242e-05 - acc: 1.0000\n",
            "Epoch 75/85\n",
            "268/268 [==============================] - 0s 563us/step - loss: 7.1542e-05 - acc: 1.0000\n",
            "Epoch 76/85\n",
            "268/268 [==============================] - 0s 534us/step - loss: 7.1642e-05 - acc: 1.0000\n",
            "Epoch 77/85\n",
            "268/268 [==============================] - 0s 527us/step - loss: 6.7514e-05 - acc: 1.0000\n",
            "Epoch 78/85\n",
            "268/268 [==============================] - 0s 502us/step - loss: 6.5275e-05 - acc: 1.0000\n",
            "Epoch 79/85\n",
            "268/268 [==============================] - 0s 511us/step - loss: 6.2623e-05 - acc: 1.0000\n",
            "Epoch 80/85\n",
            "268/268 [==============================] - 0s 505us/step - loss: 6.0276e-05 - acc: 1.0000\n",
            "Epoch 81/85\n",
            "268/268 [==============================] - 0s 538us/step - loss: 5.7798e-05 - acc: 1.0000\n",
            "Epoch 82/85\n",
            "268/268 [==============================] - 0s 561us/step - loss: 5.5644e-05 - acc: 1.0000\n",
            "Epoch 83/85\n",
            "268/268 [==============================] - 0s 563us/step - loss: 5.4497e-05 - acc: 1.0000\n",
            "Epoch 84/85\n",
            "268/268 [==============================] - 0s 506us/step - loss: 5.1452e-05 - acc: 1.0000\n",
            "Epoch 85/85\n",
            "268/268 [==============================] - 0s 497us/step - loss: 5.1602e-05 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff667fdd048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w4CzoU-_LKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_testfiles = y_test.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZLfe24x_A92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = x_test.reshape(num_testfiles,180,1)\n",
        "y_test = y_test.reshape(num_testfiles)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxC48tvs-9zm",
        "colab_type": "code",
        "outputId": "09129668-24d4-466d-d79e-4f020c6ebbde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "model0.evaluate(x_test, y_test)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "116/116 [==============================] - 1s 4ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6796026969778126, 0.8017241420416996]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOr-5TRjDGpw",
        "colab_type": "code",
        "outputId": "437cb761-c5f8-44bf-c739-25c9f7fafcca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model0.predict(x_test[3].reshape(1,180,1)).argmax()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}